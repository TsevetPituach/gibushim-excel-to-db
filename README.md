Excel to PostgreSQL Importer

- Reads an Excel file where each row contains two logical records: left A–F and right P–U.
- Validates input, cross-references PostgreSQL for foreign keys, then inserts into `api_assessorevaluation`.
- Writes a CSV execution log with a line per attempted insert.

Quick Start

- Install deps: `python -m pip install -r requirements.txt`
- Run (Windows):
  - `python -m excel_to_db_code.main --excel <excel-path> --stage <stage-number> --dsn "postgresql://postgres:Rr123456!@localhost:5432/gibushim" --output logs\insert_log.csv`

The command reads the active sheet, validates, resolves IDs, inserts rows, and logs results.

CLI Options (minimal)

- `--excel` Path to Excel file (required)
- `--stage` Stage number for evaluation (required)
- `--dsn` PostgreSQL DSN (required)
- `--output` CSV log file path (default: `logs/insert_log.csv`)

Excel Mapping

- A/P: `group_id`
- B/Q: `chest_number`
- C/R: `candidate_name`
- D/S: `assessor_name`
- E/T: `grade`
- F/U: `comment`

Each row yields up to two inserts (one per half). Half 1 (A–F) uses role "מפקד קבוצה"; Half 2 (P–U) uses role "אחראי בטיחות" to resolve `api_assessoringroup`.

Database Requirements

- `api_participant(id, chest_number, ...)` must contain the `chest_number` values from Excel (resolves `soldier_id`).
- `api_assessoringroup(group_id, stage, role, myun_id, assessor_id, ...)` must contain rows for both roles.
- `api_assessorevaluation.id` must auto-generate (Postgres 10+):
  - `ALTER TABLE public.api_assessorevaluation ALTER COLUMN id ADD GENERATED BY DEFAULT AS IDENTITY;`
  - Ensure a primary key on `id`.

Validation & Execution Logs

- Validation errors are saved to `logs/validation_errors.csv`.
- Execution CSV log contains: grade, comment, stage, assessor_id, myun_id, soldier_id, status (inserted/skipped).

Offline Usage (wheelhouse + vendor)

- Build wheelhouse online for your exact Python version:
  - `python -m pip download -r requirements.txt -d wheelhouse`
- Install offline into `vendor/`:
  - `python -m pip install --no-index --find-links wheelhouse --target vendor -r requirements.txt`
- Ensure `sitecustomize.py` is at the project root (adds `vendor/` to `sys.path`).
- Run from the project root: `python -m excel_to_db_code.main --excel <excel-path> --stage <stage-number> --dsn "postgresql://postgres:Rr123456!@localhost:5432/gibushim" --output logs\insert_log.csv`

Notes
- Uses parameterized queries and a single transaction for performance/safety.
- Tested with Python 3.8+.

